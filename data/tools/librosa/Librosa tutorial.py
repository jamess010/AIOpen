# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.4'
#       jupytext_version: 1.1.1
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
#
# # Librosa tutorial
#
# - Version: 0.6.3
# - Tutorial home: https://github.com/librosa/tutorial
# - Librosa home: http://librosa.github.io/
# - User forum: https://groups.google.com/forum/#!forum/librosa

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# ## ç¯å¢ƒ
#
# å‡è®¾å·²ç»å®‰è£…äº† [Anaconda](https://anaconda.org/).
#
# å¦‚æœæ²¡æœ‰ç¯å¢ƒï¼Œä½¿ç”¨ä¸‹é¢å‘½ä»¤åˆ›å»ºä¸€ä¸ªï¼š
#
# ```bash
# conda create --name YOURNAME scipy jupyter ipython
# ```
# (ä½¿ç”¨ `YOURNAME` æ¥ä»£æ›¿æ–°çš„ç¯å¢ƒå)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ç„¶åä½¿ç”¨ä¸‹é¢å‘½ä»¤æ¥æ¿€æ´»æ–°çš„ç¯å¢ƒï¼š
# ```bash
# source activate YOURNAME
# ```
#

# + {"slideshow": {"slide_type": "fragment"}, "cell_type": "markdown"}
# ## å®‰è£… librosa
# Librosa ä½¿ç”¨ä¸‹é¢å‘½ä»¤è¿›è¡Œå®‰è£… [ğŸ”—]:
#
# ```bash
# conda install -c conda-forge librosa
# ```
#
# æ³¨æ„ï¼šWindows éœ€è¦å•ç‹¬å®‰è£…éŸ³é¢‘è§£ç åº“ï¼Œè¿™é‡Œæ¨èä½¿ç”¨ [ffmpeg](http://ffmpeg.org/).

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## æµ‹è¯•

# + {"slideshow": {"slide_type": "-"}, "cell_type": "markdown"}
# å¼€å§‹ Jupyter:
# ```bash
# jupyter notebook
# ```
# ç„¶åæ‰“å¼€ä¸€ä¸ªnotebookï¼Œæ‰§è¡Œä¸‹é¢å‘½ä»¤ï¼š

# + {"slideshow": {"slide_type": "-"}}
import librosa
print(librosa.__version__)

# + {"slideshow": {"slide_type": "fragment"}}
y, sr = librosa.load(librosa.util.example_audio_file())
print(len(y), sr)
# -

# ### æ³¨ï¼šä¸Šé¢çš„loadçš„ç¼ºçœsr=22050ï¼Œå¦‚æœéœ€è¦åŸå§‹çš„éŸ³é¢‘é‡‡æ ·ç‡sr=None

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # librosaæ–‡æ¡£!
#
#
# Librosaæœ‰å¤§é‡çš„ä¾‹å­æ–‡æ¡£ï¼Œè¯·å‚é˜…ï¼šhttp://librosa.github.io/librosa/

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # çº¦å®š
#
# - æ‰€æœ‰æ•°æ®æ˜¯åŸºæœ¬çš„ `numpy` ç±»å‹
# - **Audio buffers**ï¼ˆéŸ³é¢‘æ•°æ®ç¼“å­˜ï¼‰ ç§°ä¸º `y`
# - **Sampling rate**ï¼ˆé‡‡æ ·ç‡ï¼‰ç§°ä¸º `sr`
# - The last axis is time-like:
#         y[1000] æ˜¯ç¬¬1001å„æ ·æœ¬
#         S[:, 100] æ˜¯ç¬¬101çš„ä¸ªSçš„å¸§
# - **Defaults** ï¼ˆç¼ºçœï¼‰`sr=22050`, `hop_length=512`

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # ä»Šå¤©è¦å­¦ä¹ çš„å†…å®¹
#
# - `librosa.core`
# - `librosa.feature`
# - `librosa.display`
# - `librosa.beat`
# - `librosa.segment`
# - `librosa.decompose`

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# # `librosa.core`
#
# - Low-level audio processesï¼ˆåº•å±‚çš„éŸ³é¢‘å¤„ç†ï¼‰
# - Unit conversionï¼ˆå•å…ƒè½¬æ¢ï¼‰
# - Time-frequency representationsï¼ˆæ—¶é—´-é¢‘ç‡å˜æ¢ï¼‰

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
#
# ä½¿ç”¨åŸå§‹é‡‡æ ·ç‡åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨ `sr=None`

# + {"slideshow": {"slide_type": "-"}}
y_orig, sr_orig = librosa.load(librosa.util.example_audio_file(),
                     sr=None)
print(len(y_orig), sr_orig)

# + {"slideshow": {"slide_type": "fragment"}, "cell_type": "markdown"}
# Resampling is easyï¼ˆé‡æ–°é‡‡æ ·éå¸¸å®¹æ˜“ï¼‰

# + {"slideshow": {"slide_type": "-"}}
sr = 22050

y = librosa.resample(y_orig, sr_orig, sr)

print(len(y), sr)

# + {"slideshow": {"slide_type": "fragment"}, "cell_type": "markdown"}
# But what's that in seconds?ï¼ˆä½†æ˜¯æ—¶é—´å¤šé•¿ï¼Ÿï¼‰

# + {"slideshow": {"slide_type": "-"}}
print(librosa.samples_to_time(len(y), sr))

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## é¢‘è°±è¡¨ç¤º
#
# çŸ­æ—¶å‚…ç«‹å¶å˜æ¢æ˜¯ä¿¡å·å¤„ç†çš„åŸºç¡€ã€‚
#
# `librosa.stft` è¿”å›ä¸€ä¸ªå¤æ•°çŸ©é˜µ `D`.
#
# `D[f, t]` æ˜¯ï¼šä»¥é¢‘ç‡ `f`, æ—¶é—´ï¼ˆå¸§ï¼‰ `t` çš„ FFT å€¼ .

# + {"slideshow": {"slide_type": "fragment"}}
D = librosa.stft(y)
print(D.shape, D.dtype)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# Often, we only care about the magnitude.ï¼ˆé€šå¸¸ï¼Œæˆ‘ä»¬æ¯”è¾ƒå…³å¿ƒå¹…å€¼ï¼‰
#
# `D` åŒ…å«å¹…å€¼ *magnitude* `S` å’Œç›¸è§’ *phase* $\phi$.
#
# $$
# D_{ft} = S_{ft} \exp\left(j \phi_{ft}\right)
# $$
# -

import numpy as np 

S, phase = librosa.magphase(D)
print(S.dtype, phase.dtype, np.allclose(D, S * phase))

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## Constant-Q transforms (æ’Qå˜æ¢)
#
# CQTæŒ‡ä¸­å¿ƒé¢‘ç‡æŒ‰æŒ‡æ•°è§„å¾‹åˆ†å¸ƒï¼Œæ»¤æ³¢å¸¦å®½ä¸åŒã€ä½†ä¸­å¿ƒé¢‘ç‡ä¸å¸¦å®½æ¯”ä¸ºå¸¸é‡Qçš„æ»¤æ³¢å™¨ç»„ã€‚å®ƒä¸å‚…ç«‹å¶å˜æ¢ä¸åŒçš„æ˜¯ï¼Œå®ƒé¢‘è°±çš„æ¨ªè½´é¢‘ç‡ä¸æ˜¯çº¿æ€§çš„ï¼Œè€Œæ˜¯åŸºäºlog2ä¸ºåº•çš„ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®è°±çº¿é¢‘ç‡çš„ä¸åŒè¯¥æ”¹å˜æ»¤æ³¢çª—é•¿åº¦ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚ç”±äºCQTä¸éŸ³é˜¶é¢‘ç‡çš„åˆ†å¸ƒç›¸åŒï¼Œæ‰€ä»¥é€šè¿‡è®¡ç®—éŸ³ä¹ä¿¡å·çš„CQTè°±ï¼Œå¯ä»¥ç›´æ¥å¾—åˆ°éŸ³ä¹ä¿¡å·åœ¨å„éŸ³ç¬¦é¢‘ç‡å¤„çš„æŒ¯å¹…å€¼ï¼Œå¯¹äºéŸ³ä¹çš„ä¿¡å·å¤„ç†æ¥è¯´ç®€ç›´å®Œç¾ã€‚
#

# +
C = librosa.cqt(y, sr=sr)

print(C.shape, C.dtype)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## ç»ƒä¹  0
#
# - Load a different audio file ï¼ˆåŠ è½½ä¸€ä¸ªä¸åŒçš„éŸ³é¢‘æ–‡ä»¶ï¼‰
# - Compute its STFT with a different hop lengthï¼ˆä½¿ç”¨ä¸åŒçš„hopé•¿åº¦æ¥è®¡ç®—å®ƒçš„STFSï¼‰

# + {"slideshow": {"slide_type": "subslide"}}
# Exercise 0 solution

y2, sr2 = librosa.load(   )

D = librosa.stft(y2, hop_length=   )

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # `librosa.feature`
#
# - Standard features:
#     - `librosa.feature.melspectrogram`
#     - `librosa.feature.mfcc`
#     - `librosa.feature.chroma`
#     - Lots more...
# - Feature manipulation:
#     - `librosa.feature.stack_memory`
#     - `librosa.feature.delta`

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# Most features work either with audio or STFT input

# +
melspec = librosa.feature.melspectrogram(y=y, sr=sr)

# Melspec assumes power, not energy as input
melspec_stft = librosa.feature.melspectrogram(S=S**2, sr=sr)

print(np.allclose(melspec, melspec_stft))

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # `librosa.display`
#
# - Plotting routines for spectra and waveforms
#
# - **Note**: major overhaul coming in 0.5

# + {"slideshow": {"slide_type": "subslide"}}
# Displays are built with matplotlib 
import matplotlib.pyplot as plt

# Let's make plots pretty
import matplotlib.style as ms
ms.use('seaborn-muted')

# Render figures interactively in the notebook
# %matplotlib nbagg

# IPython gives us an audio widget for playback
from IPython.display import Audio

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## Waveform display

# + {"slideshow": {"slide_type": "-"}}
plt.figure()
librosa.display.waveplot(y=y, sr=sr)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## A basic spectrogram display
# -

plt.figure()
librosa.display.specshow(melspec, y_axis='mel', x_axis='time')
plt.colorbar()

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## Exercise 1
#
# * Pick a feature extractor from the `librosa.feature` submodule and plot the output with `librosa.display.specshow`
#
#
# * **Bonus**: Customize the plot using either `specshow` arguments or `pyplot` functions

# + {"slideshow": {"slide_type": "subslide"}}
# Exercise 1 solution

X = librosa.feature.XX()

plt.figure()

librosa.display.specshow(    )

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # `librosa.beat`
#
# - Beat tracking and tempo estimation

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# The beat tracker returns the estimated tempo and beat positions (measured in frames)

# + {"slideshow": {"slide_type": "fragment"}}
tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
print(tempo)
print(beats)

# + {"slideshow": {"slide_type": "fragment"}, "cell_type": "markdown"}
# Let's sonify it!

# + {"slideshow": {"slide_type": "-"}}
clicks = librosa.clicks(frames=beats, sr=sr, length=len(y))

Audio(data=y + clicks, rate=sr)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# Beats can be used to downsample features
# -

chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
chroma_sync = librosa.feature.sync(chroma, beats)

# + {"slideshow": {"slide_type": "fragment"}}
plt.figure(figsize=(6, 3))
plt.subplot(2, 1, 1)
librosa.display.specshow(chroma, y_axis='chroma')
plt.ylabel('Full resolution')
plt.subplot(2, 1, 2)
librosa.display.specshow(chroma_sync, y_axis='chroma')
plt.ylabel('Beat sync')

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # `librosa.segment`
#
# - Self-similarity / recurrence
# - Segmentation

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# Recurrence matrices encode self-similarity
#
#     R[i, j] = similarity between frames (i, j)
#     
# Librosa computes recurrence between `k`-nearest neighbors.

# + {"slideshow": {"slide_type": "-"}}
R = librosa.segment.recurrence_matrix(chroma_sync)

# + {"slideshow": {"slide_type": "fragment"}}
plt.figure(figsize=(4, 4))
librosa.display.specshow(R)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# We can include affinity weights for each link as well.

# + {"slideshow": {"slide_type": "-"}}
R2 = librosa.segment.recurrence_matrix(chroma_sync,
                                       mode='affinity',
                                       sym=True)

# + {"slideshow": {"slide_type": "fragment"}}
plt.figure(figsize=(5, 4))
librosa.display.specshow(R2)
plt.colorbar()

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## Exercise 2
#
# * Plot a recurrence matrix using different  features
# * **Bonus**: Use a custom distance metric

# + {"slideshow": {"slide_type": "subslide"}}
# Exercise 2 solution

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # `librosa.decompose`
#
# - `hpss`: Harmonic-percussive source separation
# - `nn_filter`: Nearest-neighbor filtering, non-local means, Repet-SIM
# - `decompose`: NMF, PCA and friends

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# Separating harmonics from percussives is easy

# +
D_harm, D_perc = librosa.decompose.hpss(D)

y_harm = librosa.istft(D_harm)

y_perc = librosa.istft(D_perc)

# + {"slideshow": {"slide_type": "fragment"}}
Audio(data=y_harm, rate=sr)
# -

Audio(data=y_perc, rate=sr)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# NMF is pretty easy also!
# -

# Fit the model
W, H = librosa.decompose.decompose(S, n_components=16, sort=True)

plt.figure(figsize=(6, 3))
plt.subplot(1, 2, 1), plt.title('W')
librosa.display.specshow(librosa.logamplitude(W**2), y_axis='log')
plt.subplot(1, 2, 2), plt.title('H')
librosa.display.specshow(H, x_axis='time')

# + {"slideshow": {"slide_type": "subslide"}}
# Reconstruct the signal using only the first component
S_rec = W[:, :1].dot(H[:1, :])

y_rec = librosa.istft(S_rec * phase)

# + {"slideshow": {"slide_type": "-"}}
Audio(data=y_rec, rate=sr)

# + {"slideshow": {"slide_type": "subslide"}, "cell_type": "markdown"}
# ## Exercise 3
#
# - Compute a chromagram using only the harmonic component
# - **Bonus**: run the beat tracker using only the percussive component

# + {"slideshow": {"slide_type": "slide"}, "cell_type": "markdown"}
# # Wrapping up
#
# - This was just a brief intro, but there's lots more!
#
# - Read the docs: http://librosa.github.io/librosa/
# - And the example gallery: http://librosa.github.io/librosa_gallery/
# - We'll be sprinting all day.  Get involved! https://github.com/librosa/librosa/issues/395
